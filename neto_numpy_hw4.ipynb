{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrLEvfuqBJR5syaJ5zzWAP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benji8bit/NetoNUMPY_53/blob/main/neto_numpy_hw4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Задание 1**\n",
        "> **Обязательная часть**\n",
        "Будем парсить страницу со свежеми новостям на [habr.com/ru/all/](https://habr.com/ru/all/).\n",
        "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово. Эти слова определяем в начале кода в переменной, например:\n",
        "KEYWORDS = ['python', 'парсинг']\n",
        "Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы).\n",
        "В итоге должен формироваться датафрейм вида: <дата> - <заголовок> - <ссылка>"
      ],
      "metadata": {
        "id": "Uyas0cqUgV21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('../')\n",
        "from library.habr.lib import HabrPage\n",
        "\n",
        "habrPage = HabrPage.from_internet()"
      ],
      "metadata": {
        "id": "s8YGNuOngY_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "keywords = ['powerpoint', 'бизнес']\n",
        "posts = habrPage.find_by_keywords(keywords)\n",
        "\n",
        "titles = [post.title for post in posts]\n",
        "times = [post.time for post in posts]\n",
        "urls = [post.url for post in posts]\n",
        "\n",
        "pd.DataFrame({'заголовок': titles, 'дата': times, 'ссылка': urls})"
      ],
      "metadata": {
        "id": "kAQ0F_pRhVS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# > Дополнительная часть (необязательная)\n",
        "Улучшить скрипт так, чтобы он анализировал не только preview-информацию статьи, но и весь текст статьи целиком.\n",
        "Для этого потребуется получать страницы статей и искать по тексту внутри этой страницы.\n",
        "Итоговый датафрейм формировать со столбцами: <дата> - <заголовок> - <ссылка> - <текст_статьи>"
      ],
      "metadata": {
        "id": "u_LQxYQviucE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Задание 2**\n",
        "> **Обязательная часть**\n",
        "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса Avast Hack Ckeck. Список email-ов задаем переменной в начале кода:\n",
        "EMAIL = [xxx@x.ru, yyy@y.com]\n",
        "В итоге должен формироваться датафрейм со столбцами: <почта> - <дата утечки> - <источник утечки> - <описание утечки>\n",
        "Подсказка: сервис работает при помощи \"скрытого\" API. Внимательно изучите post-запросы."
      ],
      "metadata": {
        "id": "4DDBm9yBgZYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Получаем данные из API"
      ],
      "metadata": {
        "id": "Ynbi769qj9rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "EMAIL = [\"xxx@x.ru\", \"yyy@y.com\"]\n",
        "\n",
        "url = \"https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data\"\n",
        "data = {\"emailAddresses\": EMAIL}\n",
        "headers = {\n",
        "    \"Vaar-Version\": \"0\",\n",
        "    \"Vaar-Header-App-Product\": \"hackcheck-web-avast\",\n",
        "    \"Vaar-Header-App-Product-Name\": \"hackcheck-web-avast\",\n",
        "    \"Vaar-Header-App-Build-Version\": \"1.0.0\",\n",
        "}\n",
        "r = requests.post(url=url, data=json.dumps(data), headers=headers)"
      ],
      "metadata": {
        "id": "ESIiL_m3gZkN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Формируем датафрейм по утечкам"
      ],
      "metadata": {
        "id": "KL75QGUjjN6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def generate_breaches_dataframe(avast_response):\n",
        "    avast_response_json = avast_response.json()\n",
        "\n",
        "    breaches = pd.DataFrame()\n",
        "    for breach in avast_response_json['breaches'].values():\n",
        "        # remove extra column\n",
        "        del breach['statistics']\n",
        "        # parse datetime\n",
        "        breach['publishDate'] = pd.to_datetime(breach['publishDate'])\n",
        "        # generate dataframe for one record\n",
        "        df = pd.DataFrame(breach.values(), index=breach.keys())\n",
        "        # transpose and accumulate it\n",
        "        breaches = breaches.append(df.T)\n",
        "\n",
        "    return breaches.reset_index(drop=True)\n",
        "\n",
        "breaches = generate_breaches_dataframe(r)\n",
        "breaches.head()"
      ],
      "metadata": {
        "id": "nVHEGMHDjI-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Формируем датафрейм по ящикам"
      ],
      "metadata": {
        "id": "yNleZQ4hjaDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_emails_dataframe(avast_response):\n",
        "    emails = pd.DataFrame()\n",
        "    for email, breaches in r.json()['summary'].items():\n",
        "        # prepare list of id\n",
        "        breachIds = list(breaches.values())[0]\n",
        "        # generate dataframe and transpose\n",
        "        df = pd.DataFrame.from_dict({'email': [email], 'breachId': breachIds}, orient='index').T\n",
        "        # for every breachId set current email\n",
        "        df.email.fillna(email, inplace=True)\n",
        "        # accumulate dataframes\n",
        "        emails = emails.append(df)\n",
        "\n",
        "    return emails.reset_index(drop=True)\n",
        "\n",
        "\n",
        "emails = generate_emails_dataframe(r)\n",
        "emails.head()"
      ],
      "metadata": {
        "id": "8yklUM3njfXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Мержим датафреймы и выводим результат"
      ],
      "metadata": {
        "id": "ZdXCryl2jh4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged = emails.merge(breaches, on='breachId')\n",
        "merged[['email', 'publishDate', 'site', 'description']]"
      ],
      "metadata": {
        "id": "pj76Hdwzjl5k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}